---
title: '유니티 UI 제대로 이해하기'
parmalink : /study/2025-07-12
date: 2025-07-12
tags:
  - UI
  - Com2us TA Campus
---

# UI 

UI는 게임의 사용자가 게임을 직접적으로 마주하는 첫 번째 기능이자 이미지이다. 아무리 게임플레이가 탄탄하고 그래픽이 멋져도, UI가 느리거나 빠릿빠릿하게 반응하지 않는다면, 유저는 그 순간부터 이 게임 구리다라고 판단하게 된다. 때문에 UI 최적화는 단순히 성능 점수를 몇 점 올리는 게 아니라, 유저에게 보여지는 게임 전체의 첫인상을 결정하는 핵심 포인트라고도 표현 할 수 있다.



#### 빠릿한 UI

UI또한 3D 공간처럼 매 프레임마다 그려진다. 그래서 조금만 최적화가 안 돼도 바로 게임 전체 프레임에 직접적인 영향을 준다. 메뉴를 넘길 때, 리스트 스크롤이나 애니메이션이 버벅이면 게임 그래픽 화면이 버벅이는 것보다 유저는 훨씬 더 큰 불만을 가질 수 있다. 보통, UI는 스크롤과 같은 기능을 많이 포함하고 있기 때문에 60f은 필수다. 

그리고 UI 프레임 뿐만 아니라 버튼 클릭, 메뉴 이동, 탭 전환이 즉각적이어야 한다. UI 작동이 0.1초만 늦어져도 유저는 "이거 왜 이렇게 느려?"라고 바로 느낀다. 이런 버벅이고 느린 UI들은 게임의 직접적인 매출 타격 요인이 된다. 

결국 UI 최적화는 "게임이 잘 팔리는가?", "유저 UX 측면에서의 불편함은 없는가?"와 같은 근본적인 문제와 연결된다. 때문에 유저가 '빠르고 부드럽다'라고 느낄 수 있도록 개발 초기부터 신경 써야한다.



사실 UI 최적화의 경우 아티스트의 역할도 중요하지만 UI 작동을 설계하는 역할은 대부분 클라이언트 프로그래머가 하기 때문에 UI의 성능 이슈에 대해 잘 모르는 아티스트들이 많을 것이라고 생각한다.

이 글에선, 너무 깊게 들어가지 않고 정말 아티스트가 알면 좋습니다! 정도의 내용으로 유니티 UI 기능에 대해 설명할 예정이다.





## UI Canvas

Unity에서 UI는 **Canvas 시스템**을 기반으로 렌더링된다. 이 때 UI가 그려지는 순서는 다음과 같다:

- **Canvas ➡️ Panel ➡️ Graphic (Image/Text 등)**

Canvas는 UI의 '도화지'라고 생각하면 된다. 여러 Graphic 요소를 한 번에 처리한다.





모든 UI 요소는 반드시 **Canvas** 안에 있어야 한다. 

UI 이미지를 만들든, 버튼을 만들든, 처음에 캔버스가 없으면 Unity가 알아서 하나 만들어주고, 그 밑에 자동으로 UI 오브젝트가 붙는다.

씬 뷰에서 보면 캔버스 영역이 사각형으로 표시되기 때문에, 굳이 게임 뷰를 켜지 않아도 씬뷰에서 UI를 원하는 위치에 쉽게 배치할 수 있다. 그리고, 캔버스가 있으면 항상 **EventSystem 오브젝트**가 따라오는데, 이건 UI 버튼 클릭이나 각종 인터랙션 이벤트 처리를 담당하는 시스템이다.

![image-20250716053817857](./../images/2025-07-12-%EA%B0%80%EC%A0%9C1/image-20250716053817857.png)



캔버스 내부에 있는 UI들은 계층 구조(Hierarchy) 순서대로 그려진다. 맨 위에 있는 자식이 가장 먼저, 그 다음이 그 다음으로, 이런 식으로 순서대로 그려진다. 만약 이미지 두 개가 겹친다면, 나중에 그려지는(아래에 있는) 요소가 캔버스 상에선 위에 보이게 된다.

만약 어떤 UI 오브젝트가 다른 것보다 위에 나오게 하고 싶다면 그냥 Hierarchy에서 순서를 위로 끌어올리면 된다. 스크립트로도 UI 그리기 순서를 쉽게 바꿀 수 있다.



### Canvas Screen Space

UI 캔버스의 **Screen Space** 모드는 UI를 어떤 화면 기준으로 그려줄까에 대한 내용이다.



#### 1️⃣ Screen Space - Overlay

![화면 공간 오버레이 캔버스의 UI](./../images/2025-07-12-%EA%B0%80%EC%A0%9C1/GUI_Canvas_Screenspace_Overlay.png)

별도 카메라 없이 화면 최상단에 바로 렌더링되며 모든 3D 오브젝트보다 앞에 표시된다. 해상도가 변해도 UI 크기가 유지되는 것도 장점이다.

좋은 성능 또한 특징이다. 카메라 렌더링 과정을 생략해 오버헤드가 최소화되고, 별도 설정 없이 즉시 사용할 수 있어 구현이 단순하다. 3D 씬과 완전히 분리되어 3D 오브젝트와의 충돌 위험도 없다.

하지만 이펙트 출력이 불가능하다는 치명적인 단점이 있다. 3D 공간이 아니기 때문에 파티클이나 VFX 그래프처럼 깊이 정보가 필요한 정보들은 해당 캔버스에 넣을 수 없다. Post-processing 효과 적용도 제한된다.

게임 HUD(체력바, 미니맵, 점수)나 메인 메뉴, 설정 화면, 알림 팝업, 로딩 화면같은 대부분의 UI 출력에 사용된다.





#### 2️⃣ Screen Space - Camera

![화면 공간 카메라 캔버스의 UI](./../images/2025-07-12-%EA%B0%80%EC%A0%9C1/GUI_Canvas_Screenspace_Camera.png)

말 그대로 카메라를 사용한다. Render Camera에 지정된 카메라를 통해 UI가 렌더링된다.

**VFX 사용도** 가능해진다!! 파티클과 UI의 깊이 순서를 제어할 수 있고, Bloom이나 DOF 같은 후처리 효과도 적용할 수 있다. 3D 공간 내에서 UI 위치를 유연하게 조절하는 것도 가능하다.

하지만 **오버레이 기능에 비하면 성능 문제**가 발생할 수 있다는 단점이 있다. 추가 카메라 렌더링으로 성능 비용이 증가하고, 카메라 설정에 따라 UI 크기가 변동될 수 있어 해상도 의존적이기도 하다.







#### 3️⃣ World Space

![월드 공간 캔버스의 UI](./../images/2025-07-12-%EA%B0%80%EC%A0%9C1/GUI_Canvas_Worldspace.png)

UI가 실제 3D 공간의 오브젝트로 존재하며, Transform을 통한 위치, 회전, 크기 조절이 가능하다. Collider 등과의 물리적 상호작용도 할 수 있다.

일반 오브젝트처럼 제어가 가능하다는 것이 최대 장점이다. 3D 공간에서 자유로운 배치와 변형이 가능하고, 게임 세계와 완전히 통합된 UI로 몰입감을 높일 수 있다. VR/AR에서의 3차원 공간 UI 표현에 이상적이다.

하지만 가장 많은 성능 비용이 든다. VR/AR 인터페이스나 인게임 3D UI(상점 간판, 정보 패널)에 적합하다.

<a href="https://docs.unity3d.com/kr/530/Manual/UICanvas.html">이미지 출처 : Unity Documentation/캔버스</a>



| 어떤 성능 차이가 있는가...                                   |
| ------------------------------------------------------------ |
| <img src="./../images/2025-07-12-%EA%B0%80%EC%A0%9C1/image-20250714013028181.png" alt="image-20250714013028181" style="zoom:33%;" /><br /><br />어떤 성능 차이가 있을지 세가지 타입을 비교 분석 진행해보려 했는데, 일단 간단한 UI 만으론 유의미한 차이를 찾지 못했다.<br />(오히려 드로우콜은 오버레이 타입의 경우 1 더 늘어 있었다.) <br /><br />그래도 유니티 도큐먼트나 기본적으로 가지고 있는 기능의 특성들을 통해 우리는 <br /><br />**1. 별도의 카메라 렌더링 과정이 없고,<br />2. Z-Buffer 테스트가 없음.** 이유로 오버레이 타입이 다른 두가지 타입보다 성능면에서 가벼울 것이라고 예상해 볼 수 있다. |









## 성능 최적화 (배칭)

UI에서 중요한 건 드로우콜 관리다.
동일한 이미지로 여러 UI를 배치하면 유니티에서 자동으로 배칭되면서 드로우콜이 줄어든다. 반대로 이미지 종류가 다양하거나, Canvas가 여러 개면 드로우콜이 증가 한다. 이 때문에 많이 들어본 아틀라스(이미지 모음)로 합쳐주거나, Canvas 구조를 단순하게 설계해야 하는 것이다.



![image-20250713233135317](./../images/2025-07-12-%EA%B0%80%EC%A0%9C1/image-20250713233135317.png)

위 이미지는 기본 코인 이미지를 그냥 UI 캔버스에 64개 복제해 배치한 모습이다. 따로 배칭을 묶거나 하지 않아도 하나로 구워져 나온다. 자, 그럼 다양한 이미지를 넣어보자.

![image-20250716054757489](./../images/2025-07-12-%EA%B0%80%EC%A0%9C1/image-20250716054757489.png)

![ui batching test1](./../images/2025-07-12-%EA%B0%80%EC%A0%9C1/ui%20batching%20test1.gif)

상자, 코인, 사람 이모지 이 세가지 타입의 이미지를 출력하자 위 GIF처럼 **이미지 갯수만큼 드로우 콜이 늘어나는 것**을 확인할 수 있었다. 그렇다면, 이 이미지들을 아틀라스로 하나로 합친다면?



![image-20250716054818937](./../images/2025-07-12-%EA%B0%80%EC%A0%9C1/image-20250716054818937.png)

![image-20250713235423507](./../images/2025-07-12-%EA%B0%80%EC%A0%9C1/image-20250713235423507.png)

이 이미지들을 하나로 합쳐 아틀라스화 하면, 이렇게 드로우 콜이 하나로 나온다.





자, 그럼 이 배칭을 깨보자! 모두 다른 메테리얼으로 아이콘을 그리면 어떻게 될까?

아래는 매 프레임 이미지의 컬러 속성을 바꾸는 머테리얼(인스턴스) 코인 64개를 그리는 모습이다.

![ui batching test](./../images/2025-07-12-%EA%B0%80%EC%A0%9C1/ui%20batching%20test.gif)

코인의 갯수만큼... 64개의 아이콘이 그대로 출력되어 나온다. 

UI 이미지도 3D 오브젝트와 마찬가지로 동일한 메테리얼을 기준으로 묶어 함께 그린다는 것을 알 수 있었다.



이 외에도, 아래처럼 캔버스 수를 늘리면

![image-20250713234419059](./../images/2025-07-12-%EA%B0%80%EC%A0%9C1/image-20250713234419059.png)

![ui batching test2](./../images/2025-07-12-%EA%B0%80%EC%A0%9C1/ui%20batching%20test2.gif)

늘린 캔버스 수만큼 드로우콜이 늘어나는 모습또한 볼 수 있었다.







##### 그럼 언제 캔버스를 여러개 사용하는가?

유니티 UI 캔버스는 하나의 요소가 변경되면 해당 캔버스 전체가 다시 리빌드 되므로, 자주 변경되는 동적 오브젝트와 그렇지 않은 정적 오브젝트를 분리해 그리면 하나로 모두 합쳐 그릴때보다 성능이 향상된다.

해당 내용을 GPT의 도움을 받아 간단한 테스트 환경을 만들어 볼 수 있었다.

<img src="./../images/2025-07-12-%EA%B0%80%EC%A0%9C1/image-20250716055442297.png" alt="image-20250716055442297" style="zoom: 20%;" /><img src="./../images/2025-07-12-%EA%B0%80%EC%A0%9C1/image-20250716055457195.png" alt="image-20250716055457195" style="zoom:20%;" /><br />

정적 UI 1000개와 동적 UI 500개를 두가지 상황으로 나누어 20초 동안의 평균 Draw Calls, 평균 Batches를 비교해 보았다.

- **정적, 동적 UI 캔버스를 분리해 그리기** (1번 이미지)
- **모든 UI를 하나의 캔버스에 그리기** (2번 이미지)



| 항목                                                 | 캔버스 분리                                         | 캔버스 합침                                        |
| ---------------------------------------------------- | --------------------------------------------------- | -------------------------------------------------- |
| **Canvas 배치 재계산**`UGUI.Rendering.UpdateBatches` | ● Dynamic Canvas만 Dirty→ 재계산 비용 ≈ 1 ×         | ● Static+Dynamic 모두 Dirty→ 재계산 비용 ≈ (1 + 1) |
| **DrawCall 수**                                      | ● Canvas마다 1콜 → **+1** 증가(122 ↗)               | ● 한 Canvas 1콜 → **-1** (111)                     |
| **GPU 작업량**                                       | 텍스처·머티리얼 동일 → 122 vs 111 콜 차는 비용 미미 |                                                    |
| **CPU 프레임 시간**                                  | 재계산이 줄어 **4.29 ms** (≈ +17 % 빠름)            | 배치 재계산이 커져 **5.12 ms**                     |

→ **캔버스를 나누면 DrawCall 은 다소 늘지만(±10 %) CPU 오버헤드가 훨씬 감소**한다는 UGUI 특성을 간단하게 나마 재현해 볼 수 있었다.







----

# UI와 FX

<img src="./../images/2025-07-12-%EA%B0%80%EC%A0%9C1/L3%252BlJNgLHchbMqZvBuPVhBc%253D.png" alt="img" style="zoom: 33%;" />

*2D 공간 UI 친구와 3D 공간 FX 친구의 만남...*

유니티에서 이펙트는 **Particle System(Shuriken)**이나 **VFX Graph**처럼 Renderer 컴포넌트를 사용하는 시스템으로 구현된다. 이들은 카메라의 **Z-Buffer(깊이 버퍼)**를 기준으로 렌더링된다.

그런데 UI가 Screen Space - Overlay 모드로 설정되어 있으면, UI는 무조건 화면의 최상단에 위치하기 때문에 파티클을 아무리 생성해도 UI 위에 나타나지 않는다. UI와 이펙트가 서로 섞일 일이 없다는 점에서는 간편할 수도 있지만, UI 요소와 이펙트가 자연스럽게 어우러지는 연출을 구현하고 싶다면 이 점이 큰 제약이 될 수 있다.



----

➕여담 : 글을 작성하면서, Unity Particle System을 **Shuriken**이라고 부르는걸 처음 알게 되었다.

공식적인 설명은 없지만, Shuriken(手裏剣)은 일본의 던지는 무기로, 빠르게 날아가며 퍼지는 특성이 있다. 이런 특성들이 파티클들이 빠르게 방사되며 퍼져나가는 모습과 비슷해 붙여진게 아닐까 추측된다. 

----



이러한 이유로 기본적으로 유니티의 UI 캔버스는 Particle System이나 VFX Graph와 같은 이펙트를 직접 지원하지 않는다.

또한 유니티 UI에서 사용하는 마스크 기능은 기본적으로 **UI 렌더러에만 작동**한다. 그래서 만약 파티클이나 VFX와 같은 이펙트를 UI 마스크 영역 내에서 표현하려면, RenderTexture나 커스텀 셰이더를 통해 Clip 처리를 따로 구현해야 한다. 



## 🚩Unity User Package - ParticleEffectForUGUI

이런 고민을 해결해주는 패키지가 없나 찾아보다가, <a href="https://github.com/mob-sakai/ParticleEffectForUGUI">**ParticleEffectForUGUI**</a>라는 Github 프로젝트를 발견했다.



이 패키지는 유니티의 **ParticleSystemRenderer.BakeMesh** API를 활용해서 UI의 Z-버퍼 문제를 해결한다. 

- **CanvasRenderer를 통한 렌더링**
   파티클을 일반적인 3D 공간에서 직접 렌더링하지 않고, **CanvasRenderer**를 통해 이펙트를 UI 시스템의 일부로 포함시킨다. 이렇게 하면 파티클도 자연스럽게 UI 요소처럼 관리된다.
- **Mesh Baking**
   파티클 시스템의 메시 상태를 **정적인 UI 버텍스 데이터로 변환**하여 UI 렌더링 파이프라인과 합체시킨다. 이를 통해 파티클 이펙트가 일반 UI와 동일한 렌더링 순서를 갖게 되어, 더 이상 깊이 문제가 발생하지 않는다.



| BakeMesh API 란?                                             |
| ------------------------------------------------------------ |
| ParticleSystemRenderer의 상태를 스냅샷 형태로 캡처해 정적 메시에 저장하는 Unity의 API이다.<br/><br/>위 사례에선 이런식으로 사용된다:<br/>① BakeMesh를 사용해 파티클 시스템의 상태를 메시로 변환 →<br/>② 변환된 메시에서 GetVertices로 버텍스 데이터를 얻음 →<br/>③ 얻어낸 버텍스를 UI 좌표계로 변환하는 작업을 추가 수행<br/> |



<img src="./../images/2025-07-12-%EA%B0%80%EC%A0%9C1/image-20250713225518926.png" alt="image-20250713225518926" style="zoom:67%;" />

패키지를 프로젝트에 추가하면, UI 메뉴에서 **Particle System** 항목이 새로 생긴다. 

이를 활용하면 기존의 UI 요소를 다루는 것과 똑같은 방법으로 파티클 이펙트를 쉽게 생성하고 배치할 수 있다. 버튼이나 패널과 같은 일반적인 UI 위에서도 자연스럽게 파티클을 표현할 수 있기 때문에, 더 생동감 있는 UI 연출이 가능해진다.



![UI PARTICLE TEST](./../images/2025-07-12-%EA%B0%80%EC%A0%9C1/UI%20PARTICLE%20TEST.gif)

실제로 캔버스 위에 파티클 시스템을 추가하고, 버튼을 클릭했을 때 파티클이 재생되는 간단한 기능을 제작해 보았다. 

해당 패키지 덕분에 더 이상 추가적인 렌더링 카메라나 복잡한 렌더 텍스처 처리를 하지 않아도 돼 아티스트 친화적으로 UI 이펙트를 추가할 수 있었다.





## 결론

결론적으로 UI는 게임의 첫인상을 결정하는 핵심 요소이며, 최적화된 UI는 곧 유저가 게임을 부드럽고 완성도 높다고 느끼게 만드는 결정적인 역할을 한다고 볼 수 있다. 

리소스를 제작하는 아티스트 입장에선 배칭을 통한 드로우콜 관리, 동적·정적 요소의 캔버스 분리 등 기본적인 최적화 원칙이해하고 이를 지키는 것이 매우 중요하다. Canvas 유형과 구조 설계를 신중히 해 성능과 연출의 균형을 잡을 수 있도록 노력해야 한다.

또, 유니티에서 UI Canvas와 VFX를 동시에 사용하려면, 각 Canvas 타입(Screen Space - Overlay, Camera, World Space)의 특징과 장단점을 명확히 이해하고 활용해야 한다.

**아는 것이 힘이라는 말 처럼, 작업자가 UI와 이펙트의 렌더링 파이프라인과 최적화 원리를 이해하고 있다면 보다 자유롭고 창의적인 연출을 더 넓은 아이디어 차원에서 만들어 낼 수 있을 것이라 생각한다.**









